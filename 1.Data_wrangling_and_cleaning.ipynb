{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrangling Twitter data\n",
    "In this notebook, we are going to start out with the raw Twitter data that was captured using the Tweepy tool on which you can read more about in [this notebook](0.Tweepy_Bot.ipynb). The data captured was restricted to tweets from Alberta from February 25th  2019 to March 1st 2019. \n",
    "\n",
    "In order to prep the data for analysis, we will \"wrangle\" the data to clean it and structure it into a more useful format. \n",
    "\n",
    "## Goal: \n",
    "Learn some common aspects of data wrangling and convert the data set into a format more practical for further data exploration and analysis. \n",
    "\n",
    "\n",
    "## Data wrangling introduction\n",
    "[Data wrangling](https://en.wikipedia.org/wiki/Data_wrangling) \"is the process of transforming and mapping data from one \"raw\" data form into another format with the intent of making it more appropriate and valuable for a variety of downstream purposes such as analytics\" (Wikipedia).\n",
    "\n",
    "The purpose of data wrangling notebook is to transform complex data into a format that is easier to work with in order to focus on the analysis of data, rather than the wrangling in the next notebooks. \n",
    "\n",
    "#### Common data wrangling steps:\n",
    " - **Discovering**  - understanding the data\n",
    " - **Structuring** -  organizing the data\n",
    "     - Naming or renaming variables\n",
    "     - Changing the type of variables\n",
    "     - Creating new variables through functions of existing of variables\n",
    "     - Conditional processing of variables (i.e the values of new variable is based on the values of existing variables) \n",
    " - **Cleaning** \n",
    "     - Redesign the data into a usable/functional format and correct/remove any bad data\n",
    "     - Imputing missing values in a variables\n",
    " - **Publishing**\n",
    "    - Selecting columns from input dataset to output dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load python modules\n",
    "\n",
    "There are many packages available in Python that provide a variety of functions for data science. Here we load the libraries needed for this notebook. \n",
    "\n",
    "One of the most common libraries used for data science is [pandas](https://pandas.pydata.org/). There are good tutorials available on pandas and worthwhile spending more time with in order to become more comfortable with data science in python. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import urllib.request\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import ast"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1. Taking a look at the raw data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading the Twitter data  and displaying the first 5 rows\n",
    "\n",
    "The raw data(`tweets.txt`) is stored in the same directory, we will read it into a pandas DataFrame. A **DataFrame** is a commonly encountered way to work with data in data science. It can be thought of as a 2D data structure that makes it easy to work with the data at hand. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#target_url=\"https://swift-yeg.cloud.cybera.ca:8080/v1/AUTH_233e84cd313945c992b4b585f7b9125d/geeky-summit/alberta_tweets_feb_25_start.txt\"\n",
    "file_name=\"../data-science-for-entrepreneurs-helper/alberta_tweets_feb_25_start.txt\"\n",
    "\n",
    "## comment out this line to use your local copy \n",
    "#urllib.request.urlretrieve(target_url, file_name)\n",
    "\n",
    "tweets = []\n",
    "with open(file_name, 'r') as f:\n",
    "    for lines in f.readlines():\n",
    "        tweets.append(ast.literal_eval(lines))\n",
    "tweets  = pd.DataFrame(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets.head(5) # head is a convenient way for showing the first few rows of a dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Understanding the raw data\n",
    "\n",
    "Let's take a look at some basic features of the raw data. For example, it's always a good idea to look at the columnns and the size of the data in question. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "tweets.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are several interesting features there, such as latitude and longitude of the tweets (`coordinates` column), and most of the columns make sense and are pretty intuitive. Two columns that are a bit confusing are `text` and `extended_tweet` as it looks like they may contain the same content. We should figure out if they are actually different. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Indexing in DataFrames\n",
    "\n",
    "DataFrames are convenient for working with data and are popular both in Python and R. There are a few different ways for accessing data inside a DataFrame. We'll cover a couple of aspects here, but you may also want to read more in the  pandas documentation or cheat sheet such as the one handed out [here](https://www.dataquest.io/blog/large_files/pandas-cheat-sheet.pdf). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_row', 10) #Ensure only 10 rows are displayed to save space\n",
    "pd.set_option('display.max_colwidth', -1) #Ensure output is not truncated by width\n",
    "\n",
    "#Selecting a column\n",
    "tweets[[\"text\"]] #Using two brackets displays the column as a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting two columns \n",
    "tweets[[\"text\", \"extended_tweet\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Selecting row subsets\n",
    "selectone = tweets[[\"text\", \"extended_tweet\"]].iloc[[2]] #iloc allows for selection by integers\n",
    "selecttwo = tweets[[\"text\", \"extended_tweet\"]].iloc[[2,5]] \n",
    "selectrange = tweets[[\"text\", \"extended_tweet\"]].iloc[2:5]\n",
    "\n",
    "print(selectone)\n",
    "print(selecttwo)\n",
    "print(selectrange)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select a certain row, all columns\n",
    "tweets.iloc[3,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Investigating `text` and `extended_tweet` graphically\n",
    "\n",
    "One way to investigate the difference between `text` and `extended_tweet` is to plot the length distribution for both columns. To do this, we use the [matplotlib library](https://matplotlib.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set up a plot with subplots \n",
    "plt.subplot(1, 2, 1) # (rows, columns, active plot)\n",
    "#Create a histogram, which counts the number of tweets of each length\n",
    "plt.hist(tweets[\"text\"].apply(len).values, color = 'green', edgecolor = 'black')\n",
    "#Label the plot\n",
    "plt.title('text')\n",
    "plt.xlabel('Tweet length')\n",
    "plt.ylabel('Number of tweets')\n",
    "\n",
    "# Do the same thing for the second subplot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(tweets[\"extended_tweet\"].apply(len).values, color = 'blue', edgecolor = 'black')\n",
    "plt.tight_layout()  #automatically adjusts subplot params so that the subplot(s) fits in to the figure area\n",
    "plt.title('extended_tweet')\n",
    "plt.xlabel('Tweet length')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like `extended_tweet` has much longer tweets, up to 500(or more) characters in length, whereas there are no tweets longer than 150 characters in `text`. \n",
    "\n",
    "What does the longest tweet look like? To do this, we can easily pull the longest tweet from the DataFrame. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Maximum length for extended_tweet column: \",max(tweets[\"extended_tweet\"].apply(len)), \"\\n\")\n",
    "\n",
    "print(\"This is the row number for the longest tweet:\")\n",
    "print([tweets[\"extended_tweet\"].apply(len).idxmax(axis=1)], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise1: Using the row number you determined above, add your code to display what the longest tweet looks like in the `text` and `extended_tweet` columns in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tweet as seen in the **extended_tweet** column:\\n\")\n",
    "###### Enter your code in place of None below\n",
    "extended = None\n",
    "######\n",
    "print(str(extended) + \"\\n\")\n",
    "\n",
    "print(\"Tweet as seen in the **text** column:\\n\")\n",
    "###### Enter your code in place of None below\n",
    "text_tweet = None\n",
    "######\n",
    "print(text_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer should show that the `text` column is the truncated version of `extended_tweet` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2. (Re-) structuring  the data\n",
    "\n",
    "One aspect to always pay close attention to is the data type of each column. Overlooking data types and ending up with unexpected types often leads to issues further downstream in the analysis. Here we will go through and change some of the data types to make sure they are what we want them to be. \n",
    "\n",
    "Examine DtataFrame column types/values first, this code snippet will print:\n",
    "* column name\n",
    "* column type\n",
    "* sample value in the column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in tweets.columns:\n",
    "    value=tweets[tweets[column].notnull()][column].iloc[0] #find first non empty value in the colum\n",
    "    if column==\"user_mentions\" or column==\"hashtags\":\n",
    "        value=tweets[tweets[column].apply(lambda c: c!=[])][column].iloc[0] # for column type \"list\"\n",
    "    print(\"Column name: {colname} \\nColumn type: {coltype} \\nColumn data(example): {coldata} \\n\\n\"\n",
    "          .format(colname=column, coltype=type(value),coldata=value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So we have the following list of columns:\n",
    " - **coordinates** - user coordinates, can be None or Python type Dict(needs to be split to two columns - longitude and latitude)\n",
    " - **created_at**  - creation date, Python type String (needs to be converted to type Date + timezone needs to be changed from UTC to MST)\n",
    " - **extended_tweet** - tweet text, Python type String\n",
    " - **hashtags** - hashtags, Python type List of Dicts(needs to be converted to String)\n",
    " - **lang** - language , Python type String\n",
    " - **name** - twitter account name, Python type String\n",
    " - **screen_name** - screen name, Python type String\n",
    " - **text** - truncated tweet text, Python type String\n",
    " - **user_location** - location, Python type String\n",
    " - **user_mentions** - user mentions, Python type List of Dicts(needs to be converted to String)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned = tweets #create a copy of tweets dataframe, will do cleaning using this copy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert column `created_at`  from String to Date and change timezone from UTC to MST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_cleaned[tweets_cleaned[\"created_at\"].notnull()][\"created_at\"].head()) #print first non-empty row for \"created_at\" column\n",
    "\n",
    "tweets_cleaned[\"created_at_date\"]= pd.to_datetime(tweets_cleaned[\"created_at\"]) ## convert to timestamp\n",
    "tweets_cleaned[\"created_at_date\"]=tweets_cleaned[\"created_at_date\"].dt.tz_localize('UTC').dt.tz_convert('MST')\n",
    "\n",
    "print(tweets_cleaned[tweets_cleaned[\"created_at_date\"].notnull()][\"created_at_date\"].head())  ## Print the transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert column `coordinates` from dictionary to two columns `latitude` and `longitude`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_cleaned[tweets_cleaned[\"coordinates\"].notnull()][\"coordinates\"].head()) ## Print the original data\n",
    "\n",
    "def convertCoordToList(v):  ## helper function\n",
    "    if v is None:\n",
    "        v=[]\n",
    "    else:\n",
    "        v= v['coordinates']\n",
    "    return v\n",
    "\n",
    "tweets_cleaned['coordinates_list']= tweets_cleaned['coordinates'].map(convertCoordToList) #Convert coordinates from Dict to List\n",
    "\n",
    "#Split coordinates_list column into two: latitude and longitude\n",
    "tweets_cleaned[['latitude','longitude']] = pd.DataFrame(tweets_cleaned['coordinates_list'].values.tolist())\n",
    "\n",
    "print(tweets_cleaned[tweets_cleaned[\"coordinates\"].notnull()][['longitude','latitude']].head()) ## Print the transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert column `hashtags`  from dictionary to strings\n",
    "If there were no hashtags in a cell, we will fill that cell in our dataframe with a single space `' '`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_cleaned[tweets_cleaned[\"hashtags\"].apply(lambda c: c!=[])][\"hashtags\"].head()) ## Print the original data\n",
    "\n",
    "def convertHashToString(v): ## helper function\n",
    "    if v == []:\n",
    "        v=' '\n",
    "    else:\n",
    "        v=' '.join([d['text'] for d in v])\n",
    "    return v\n",
    "\n",
    "tweets_cleaned['hashtags_string']= tweets_cleaned['hashtags'].map(convertHashToString) ## Do the conversion\n",
    "\n",
    "print(tweets_cleaned[tweets_cleaned[\"hashtags_string\"]!=' '][\"hashtags_string\"].head()) ## Print the transformed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Convert column `user_mentions` from dictionary to string\n",
    "\n",
    "We don't want the `user_mentions` column to be in a dictionary format as it is easier to work with as a string. Let's convert it.\n",
    "\n",
    "The following is a sample of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_cleaned[tweets_cleaned[\"user_mentions\"].apply(lambda c: c!=[])][\"user_mentions\"].head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise2:** Using the `hashtags` conversion above as an example, complete the following cell in order to convert the `user_mentions` column to strings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convertUserToString(v):\n",
    "    if v == []:\n",
    "        v=' '\n",
    "    else:\n",
    "        v=' '.join([d['screen_name'] for d in v])\n",
    "    return v\n",
    "\n",
    "###### Enter your code below\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your answer\n",
    "Only screen_name's should be extracted from the distionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tweets_cleaned[tweets_cleaned[\"user_string\"]!=' '][\"user_string\"].head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3. Cleaning the data\n",
    "\n",
    "Some data cleanup was done in step 2. Let's take a closer look at the `extended_tweet` column, since we will use it in further during our data analysis. \n",
    "\n",
    "First, let's look at what some of the tweets look like. We'll set an output parameter and then access the first few tweets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('max_colwidth', 700) ## Setting col_widht wider - so we can see the entire tweet\n",
    "tweets_cleaned['extended_tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Remove URLS \n",
    "There are lots of links in this column that might make our future data analysis messy and likely do not have any meaning. Let's remove them together with any links starting with www.  \n",
    "\n",
    "We will accomplish this using regular expression: **'http\\S+|www.\\S+'** (Note that **\\S+** means one or more non-whitespace character)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned['extended_tweet']=tweets_cleaned['extended_tweet'].str.replace('http\\S+|www.\\S+', '', case=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise3: remove '\\n' (new line symbol) from 'extended_tweet' column\n",
    "\n",
    "Another item that might interfere with our analysis are new line characters. Let's remove these as well in the cell below.  \n",
    "(Hint: regular expression in this case will be just one character **'\\n'**)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Enter your code below\n",
    "\n",
    "\n",
    "######"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check your answer\n",
    "Print the first 10 tweets and see if \\n is removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned['extended_tweet'].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove user mentions and hashtags from the 'extended_tweet' column and save it as 'extended_tweet_cleaned' column\n",
    "There are separate columns for user mentions and hashtags. We might need to analyse tweet text without any hashtags/user mentions. However, we might also want to do some analysis on the tweets including the mentions and hashtags. As such, tweets with these items removed will be stored in a separate column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tweets_cleaned['extended_tweet_cleaned']=tweets_cleaned['extended_tweet'].str.replace('#', '',case=False)\n",
    "tweets_cleaned['extended_tweet_cleaned'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will keep emoji, punctuation,  numbers and special characters for now. They might be useful for the analysis. We can always do more cleaning in the later notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's take a look at the language column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned[\"lang\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Column lang has only one value en so it can be safely ignored."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6. Publishing - saving data for future work\n",
    "\n",
    "In order to work with this data further, let's save a new DataFrame. \n",
    "\n",
    "We'll simply select the desired columns from the working dataset into the output dataset and take a look at the output. Does the output match what we expected? How do the `extended_tweet` and `extended_tweet_clean` columns compare? \n",
    "\n",
    "Further below, we'll save the data to a csv file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned_final=tweets_cleaned[['created_at_date','hashtags_string','user_string','user_location',\n",
    "                     'longitude','latitude','name', 'screen_name','extended_tweet','extended_tweet_cleaned']]\n",
    "tweets_cleaned_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned_final.to_csv('alberta_tweets_cleaned_feb_25.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Conclusion\n",
    "\n",
    "We've taken a preliminary look at some of the raw Twitter data that's been collected in order to further work with it. This included restructuring and reorganizing it and cleaning up the columns that we anticipate needing the most for our analysis.\n",
    "\n",
    "Take-aways: \n",
    "* We've started working with some very popular libraries for doing data science in Python: pandas and matplotlib\n",
    "* Examining, wrangling, and cleaning your data are important work that will take up large portions of time in the data science workflow\n",
    "* This is an iterative process. We took a stab at what we need to clean up and refine now, but may very well find things we've missed as we dig deeper into the data. \n",
    "\n",
    "Next, we will get into data exploration further. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Tweet as seen in the **extended_tweet** column:\\n\")\n",
    "###### Enter your code in place of None below\n",
    "extended = tweets[\"extended_tweet\"].iloc[18960]\n",
    "######\n",
    "print(str(extended) + \"\\n\")\n",
    "\n",
    "print(\"Tweet as seen in the **text** column:\\n\")\n",
    "###### Enter your code in place of None below\n",
    "text_tweet = tweets[\"text\"].iloc[18960]\n",
    "######\n",
    "print(text_tweet)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned['user_string']=tweets_cleaned[\"user_mentions\"].map(convertUserToString)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercise3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets_cleaned['extended_tweet']=tweets_cleaned['extended_tweet'].str.replace('\\n', '')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1.0,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1.0,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
